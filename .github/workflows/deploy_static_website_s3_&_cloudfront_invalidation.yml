name: >-
  Publish static Website into Production Server
  upload static assets to S3 and invalidate CloudFront

on:
  workflow_call:
    inputs:
      runs-on:
        description: Platform to execute on
        type: string
        default: ubuntu-latest
      folder_path:
        description: Folder to create website in
        type: string
        required: true
      repo_name:
        description: Name of repo
        type: string
        required: true
      source_folder:
        description: Source Directory containing files to upload
        type: string
        default: "./"
      dest_folder:
        description: Source Directory containing files to upload
        type: string
        default: "/"
      invalidation_paths:
        description: Cloudfront cache invalidation paths - Separate multiple paths with comma
        type: string
        default: "/*"

    secrets:
      SERVER_SSH_HOST:
        description: Server IP to deploy on
        required: true
      SERVER_SSH_USERNAME:
        description: Server user
        required: true
      SERVER_SSH_KEY:
        description: Server ssh key
        required: true
      SERVER_SSH_PORT:
        description: Server port to ssh into
        required: true
      AWS_ACCESS_KEY_ID:
        description: Aws Access Key Id
        required: true
      AWS_SECRET_ACCESS_KEY:
        description: Aws Secret Access Key
        required: true
      AWS_REGION:
        description: Aws Region
        required: true
      AWS_S3_BUCKET:
        description: Aws S3 Bucket
        required: true
      CLOUDFRONT_DISTRIBUTION_ID:
        description: Cloudfront Distribution Id
        required: true

jobs:
  cp-files-to-s3-invalidate-cloudfront:
    runs-on: ${{ inputs.runs-on }}
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
      SOURCE_DIR: ${{ inputs.source_folder }}
      DEST_DIR: ${{ inputs.dest_folder }}
      CLOUDFRONT_INVALIDATION_PATHS: ${{ inputs.invalidation_paths }}
      DISTRIBUTION_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}

    steps:
      - name: Checkout Repo to Upload files # Checks-out repo under $GITHUB_WORKSPACE, so your job can access it
        uses: actions/checkout@v3

      - name: Check S3 Path
        if: startsWith(env.DEST_DIR, '/') != true
        run: |
          echo "DEST_DIR=/$DEST_DIR" >> $GITHUB_ENV

      - name: Sync files to Aws S3
        run: |
          aws s3 sync $SOURCE_DIR s3://$AWS_S3_BUCKET$DEST_DIR --follow-symlinks --delete --cache-control 'public,max-age=31536000' \
          --exclude '.git/*' --exclude '.vscode/*' --exclude '*.html' --exclude '*.gitignore' --exclude '.github/*' --exclude '*.txt' --exclude 'License/*'

      - name: Check CloudFront Invalidation Path
        if: startsWith(env.CLOUDFRONT_INVALIDATION_PATHS, '/') != true
        # IFS (Internal Field Separator) is set to a comma (','), and the read command is used to split
        # the paths variable into an array called path_array. The for loop iterates over the array and
        # adds a leading slash to each path if it doesn't already have one. The modified paths are then
        # added to a new array called modified_paths. The path_array is then set to the modified_paths
        run: |
          paths="$CLOUDFRONT_INVALIDATION_PATHS"
          IFS=',' read -ra path_array <<< "$paths"
          modified_paths=()
          for path in "${path_array[@]}"; do
            if [[ ! $path =~ ^/ ]]; then
              path="/$path"
            fi
            modified_paths+=("$path")
          done
          path_array=("${modified_paths[@]}")
          echo "CLOUDFRONT_INVALIDATION_PATHS=${path_array[@]}" >> $GITHUB_ENV

      - name: Invalidate CloudFront Cache
        run: |
          aws cloudfront create-invalidation --distribution-id $DISTRIBUTION_ID \
          --paths $CLOUDFRONT_INVALIDATION_PATHS

  rsync-updates-to-server:
    needs: cp-files-to-s3-invalidate-cloudfront
    runs-on: ${{ inputs.runs-on }}
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

      - name: Deploy with rsync
        uses: burnett01/rsync-deployments@5.2.1
        env:
          DEPLOY_FOLDER: ${{ inputs.folder_path }}/${{ inputs.repo_name }}
        with:
          # use --mkpath if using Ubuntu 22.04 - --mkpath not supported in rsync 3.1.3 Ubuntu 20.04 GitHub Action Runner
          switches:
            -avzr --delete-excluded --include='*.html'  --include='License' --exclude='*'
            --rsync-path="mkdir -p $DEPLOY_FOLDER && rsync"
          path: ./
          remote_path: $DEPLOY_FOLDER
          remote_host: ${{ secrets.SERVER_SSH_HOST }}
          remote_user: ${{ secrets.SERVER_SSH_USERNAME }}
          remote_port: ${{ secrets.SERVER_SSH_PORT }}
          remote_key: ${{ secrets.SERVER_SSH_KEY }}

  ssh-deploy-website:
    needs: rsync-updates-to-server
    runs-on: ${{ inputs.runs-on }}
    steps:
      - name: SSH into Dev Server
        uses: appleboy/ssh-action@v0.1.7
        env:
          DEPLOY_FOLDER: ${{ inputs.folder_path }}/${{ inputs.repo_name }}
        with:
          host: ${{ secrets.SERVER_SSH_HOST }}
          username: ${{ secrets.SERVER_SSH_USERNAME }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          port: ${{ secrets.SERVER_SSH_PORT }}
          envs: DEPLOY_FOLDER
          script: |
            chown -R www-data:www-data $DEPLOY_FOLDER
            systemctl reload nginx
            exit
